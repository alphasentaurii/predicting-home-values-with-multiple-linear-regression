{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 1.2 - Define functions to be used\n",
    "   * def check_column(series, nlargest):\n",
    "   * def log_z(col):\n",
    "   * def rem_out_z(col_name):\n",
    "   * def multiplot(df):\n",
    "   * def plot_hist_scat(df,target,stats):\n",
    "   * def plot_hist_scat_sns(df,target,stats):\n",
    "   * def detect_outliers(df,n,features): (using IQRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarizer\n",
    "Unique Values, Non-Null Value Counts, Describe() Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def summarizer(data, column):\n",
    "    print(f\"\\n{data[column].name.upper()}\")\n",
    "    print(\"-\"*len(data[column].name))\n",
    "    print(f\"Nulls\\n{df[column].isna().sum()} out of {len(df[column])}({round(df[column].isna().sum()/len(df[column])*100,2)}%)\\n\")\n",
    "    print(f\"Unique Values:\\n {data[column].unique()}\\n\")\n",
    "    print(f\"Non-Null Value Counts:\\n{data[column].value_counts()}\\n\")\n",
    "    print(f\"Quick Stats:\\n{data[column].agg(['mean','median','std'])}\")\n",
    "    \n",
    "\n",
    "#summarizer(df, 'waterfront')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4455acfafea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Bar plot - boolean values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwaterfront_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaterfront\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Bar plot - boolean values\n",
    "\n",
    "waterfront_series = df.waterfront.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.grid(zorder=0)\n",
    "plt.bar(waterfront_series.index, waterfront_series.values, zorder=2, alpha=0.7)\n",
    "plt.xticks(waterfront_series.index, waterfront_series.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check_column\n",
    "check_column(series,nlargest='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Check columns returns the datatype, null values and unique values of input series \n",
    "def check_column(series,nlargest='all'):\n",
    "    print(f\"Column: df['{series.name}']':\")\n",
    "    print(f\"dtype: {series.dtype}\")\n",
    "    print(f\"isna: {series.isna().sum()} out of {len(series)} - {round(series.isna().sum()/len(series)*100,3)}%\")\n",
    "        \n",
    "    print(f'\\nUnique non-na values:') #,df['waterfront'].unique())\n",
    "    if nlargest =='all':\n",
    "        print(series.value_counts())\n",
    "    else:\n",
    "        print(series.value_counts().nlargest(nlargest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Check columns returns the datatype, null values and unique values of input series \n",
    "def check_column(series_feature, nlargest='all'):\n",
    "    \"\"\"\n",
    "    Takes a series from a dataframe (df[col]), \n",
    "    reports back info on unique values, nulls, .describe() stats.\n",
    "    \n",
    "    Args:\n",
    "    series (series (DataFrame column)): column to report    \n",
    "    \"\"\"\n",
    "    dashes = '---'*25\n",
    "    series=series_feature\n",
    "    \n",
    "    print(f\"Column: df['{series.name}']':\")\n",
    "    print(f\"dtype: {series.dtype}\")\n",
    "    \n",
    "    print(f\"isna: {series.isna().sum()} out of {len(series)} - {round(series.isna().sum()/len(series)*100,3)}%\")\n",
    "    print(f'\\nUnique non-na values:') #,df['waterfront'].unique())\n",
    "    if nlargest =='all':\n",
    "        print(series.value_counts())\n",
    "    else:\n",
    "        print(series.value_counts().nlargest(nlargest))\n",
    "    \n",
    "    print('\\nDescribe')\n",
    "    print(series.describe())\n",
    "    \n",
    "    if series.dtype != 'object':\n",
    "        sns.distplot(series)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"\\n{[series.name]} is a string column and cannot be plotted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['bathrooms'], df['target'])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df['bedrooms'], df['target'])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df['floors'], df['target'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub_scatter\n",
    "def sub_scatter(x_cols, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "# create variables for each seris you want to pass into the xcols list and compare them against one\n",
    "y_sub = 'sqft_living'\n",
    "sqft_sub = ['sqft_living15','sqft_above', 'sqft_lot', 'sqft_lot15']\n",
    "\n",
    "def sub_scatter(xcols, y):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16,3))\n",
    "    for xcol, ax in zip(xcols, axes):\n",
    "        df.plot(kind='scatter', x=xcol, y=y, ax=ax, alpha=0.7, color='b')\n",
    "\n",
    "sub_scatter(sqft_sub, y_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEATMAP\n",
    " basic eyeball testing using heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(data=corr.abs(), annot=True, cmap=sns.color_palette('Blues'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot_hist_scat_sns\n",
    "def plot_hist_scat_sns(df,target,stats):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "#SEABORN\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plots histogram and scatter (vs price) side by side\n",
    "def plot_hist_scat_sns(df,target='price'):\n",
    "    plt.style.use('dark_background')\n",
    "\n",
    "    \n",
    "    ## ----------- DEFINE AESTHETIC CUSTOMIZATIONS ----------- ##\n",
    "    # Axis Label fonts\n",
    "    fontTitle = {'fontsize': 16,\n",
    "               'fontweight': 'bold',\n",
    "                'fontfamily':'serif'}\n",
    "\n",
    "    fontAxis = {'fontsize': 14,\n",
    "               'fontweight': 'bold',\n",
    "                'fontfamily':'serif'}\n",
    "\n",
    "    fontTicks = {'fontsize': 12,\n",
    "               'fontweight':'bold',\n",
    "                'fontfamily':'serif'}\n",
    "\n",
    "    # Formatting dollar sign labels\n",
    "    fmtPrice = '${x:,.0f}'\n",
    "    tickPrice = mtick.StrMethodFormatter(fmtPrice)\n",
    "    \n",
    "\n",
    "    ## ----------- PLOTTING ----------- ##\n",
    "    \n",
    "    ## Loop through dataframe to plot\n",
    "    for column in df.describe():\n",
    "    \n",
    "        # Create figure with subplots for current column\n",
    "        # Note: in order to use identical syntax for large # of subplots (ax[i,j]), \n",
    "        #  declare an extra row of subplots to be removed later\n",
    "        fig, ax = plt.subplots(figsize=(12,10), ncols=2, nrows=2)\n",
    "\n",
    "        ## ----- SUBPLOT 1 -----##\n",
    "        i,j = 0,0\n",
    "        ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
    "        \n",
    "        # Define graphing keyword dictionaries for distplot (Subplot 1)\n",
    "        hist_kws = {\"linewidth\": 1, \"alpha\": 1, \"color\": 'blue','edgecolor':'w'}\n",
    "        kde_kws = {\"color\": \"white\", \"linewidth\": 1, \"label\": \"KDE\"}\n",
    "        \n",
    "        # Plot distplot on ax[i,j] using hist_kws and kde_kws\n",
    "        sns.distplot(df[column], norm_hist=True, kde=True,\n",
    "                     hist_kws = hist_kws, kde_kws = kde_kws,\n",
    "                     label=column+' histogram', ax=ax[i,j])\n",
    " \n",
    "\n",
    "        # Set x axis label\n",
    "        ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
    "    \n",
    "        # Get x-ticks, rotate labels, and return\n",
    "        xticklab1 = ax[i,j].get_xticklabels(which = 'both')\n",
    "        ax[i,j].set_xticklabels(labels=xticklab1, fontdict=fontTicks, rotation=45)\n",
    "        ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "        \n",
    "        # Set y-label \n",
    "        ax[i,j].set_ylabel('Density',fontdict=fontAxis)\n",
    "        yticklab1=ax[i,j].get_yticklabels(which='both')\n",
    "        ax[i,j].set_yticklabels(labels=yticklab1,fontdict=fontTicks)\n",
    "        ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "        \n",
    "        \n",
    "        # Set y-grid\n",
    "        ax[i, j].set_axisbelow(True)\n",
    "        ax[i, j].grid(axis='y',ls='--')\n",
    "\n",
    "        \n",
    "        ## ----- SUBPLOT 2-----  ##\n",
    "        i,j = 0,1\n",
    "        ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
    "\n",
    "        # Define the ketword dictionaries for  scatter plot and regression line (subplot 2)\n",
    "        line_kws={\"color\":\"white\",\"alpha\":0.5,\"lw\":4,\"ls\":\":\"}\n",
    "        scatter_kws={'s': 2, 'alpha': 0.5,'marker':'.','color':'blue'}\n",
    "\n",
    "        # Plot regplot on ax[i,j] using line_kws and scatter_kws\n",
    "        sns.regplot(df[column], df[target], \n",
    "                    line_kws = line_kws,\n",
    "                    scatter_kws = scatter_kws,\n",
    "                    ax=ax[i,j])\n",
    "        \n",
    "        # Set x-axis label\n",
    "        ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
    "\n",
    "         # Get x ticks, rotate labels, and return\n",
    "        xticklab2=ax[i,j].get_xticklabels(which='both')\n",
    "        ax[i,j].set_xticklabels(labels=xticklab2,fontdict=fontTicks, rotation=45)\n",
    "        ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "        # Set  y-axis label\n",
    "        ax[i,j].set_ylabel('Price',fontdict=fontAxis)\n",
    "        \n",
    "        # Get, set, and format y-axis Price labels\n",
    "        yticklab = ax[i,j].get_yticklabels()\n",
    "        ax[i,j].set_yticklabels(yticklab,fontdict=fontTicks)\n",
    "        ax[i,j].get_yaxis().set_major_formatter(tickPrice) \n",
    "\n",
    "        # Set y-grid\n",
    "        ax[i, j].set_axisbelow(True)\n",
    "        ax[i, j].grid(axis='y',ls='--')       \n",
    "        \n",
    "        ## ---------- Final layout adjustments ----------- ##\n",
    "        # Deleted unused subplots \n",
    "        fig.delaxes(ax[1,1])\n",
    "        fig.delaxes(ax[1,0])\n",
    "\n",
    "        # Optimizing spatial layout\n",
    "        fig.tight_layout()\n",
    "        figtitle=column+'_dist_regr_plots.png'\n",
    "        #plt.savefig(fig_filepath+figtitle)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Plots histogram and scatter (vs price) side by side\n",
    "def plot_hist_scat(df,target='price',stats=False):\n",
    "#     plt.style.use('bmh')\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    \n",
    "#     fontTitle = {'family': 'serif',\n",
    "#             'color':  'black',\n",
    "#             'weight': 'normal',\n",
    "#             'size': 16,\n",
    "#             }\n",
    "#     fontTicks = {'family': 'sans-serif',\n",
    "#             'color':  'black',\n",
    "#             'weight': 'normal',\n",
    "#             'size': 10,\n",
    "#             }\n",
    "    results = [['column','K_square','p-val']]\n",
    "\n",
    "    for column in df.describe():\n",
    "\n",
    "        fig = plt.figure(figsize=(8,3) )#plt.figaspect(0.5))#(5,4))\n",
    "        \n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.hist(df[column],density=True,label = column+' histogram',bins=20)\n",
    "        ax1.set_title(column.capitalize())\n",
    "\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.scatter(x=df[column], y=df[target],label = column+' vs price',marker='.')\n",
    "        ax2.set_title(column.capitalize())\n",
    "        ax2.legend()\n",
    "\n",
    "        fig.tight_layout()\n",
    "        if stats==True:\n",
    "            stat, p = normtest(df[column])\n",
    "#             print(f'Normality test for {column}:K_square = {stat}, p-value = {p}')\n",
    "\n",
    "            results.append([column,stat, p])\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corr_coef\n",
    "Combining columns to find higher correlation coefficients (creating a new feature by taking a weighted sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.linspace(0, 1, 50)\n",
    "\n",
    "best_weight = 0\n",
    "max_corr = 0\n",
    "\n",
    "for weight in weights:\n",
    "    #creating a new feature by taking a weighted sum\n",
    "    new_feature = weight*df['bathrooms'] + (1 - weight) * df['bedrooms']\n",
    "    \n",
    "    corr_coef = np.corrcoef(new_feature, df['price'])[0][1]\n",
    "    if corr_coef > max_corr:\n",
    "        max_corr = np.abs(corr_coef)\n",
    "        best_weight = weight\n",
    "    \n",
    "print(best_weight, 1 - best_weight)\n",
    "    \n",
    "#np.corrcoef(df['bathrooms'], df['price'])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot_regplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regplot(x, y):\n",
    "    sns.regplot(x=x, y=y, data=df)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "# plot_regplot('sqft_living', y='target')\n",
    "# plot_regplot('sqft_above')\n",
    "# plot_regplot('sqft_living', y='sqft_above')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLOT\n",
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multiplot(df):\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap=cmap, center=0,\n",
    "                \n",
    "    square=True, linewidths=.5, cbar_kws={\"shrink\": .5}) #\n",
    "    \n",
    "# multiplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detect_outliers\n",
    "detect_outliers(df, n, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "# Tukey's method using IQR to eliminate \n",
    "def detect_outliers(df, n, features):\n",
    "    outlier_indices = []\n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        # select observations containing more than 2 outliers\n",
    "        outlier_indices = Counter(outlier_indices)        \n",
    "        multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)\n",
    "        return multiple_outliers \n",
    "# Outliers_to_drop = detect_outliers(data,2,[\"col1\",\"col2\"])\n",
    "# df.loc[Outliers_to_drop] # Show the outliers rows\n",
    "# Drop outliers\n",
    "# data= data.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = df.columns\n",
    "#['condition', 'grade','zipcode','sqft_living', 'bathrooms']\n",
    "#outliers_to_drop = detect_outliers(df, 2, features)\n",
    "#df.loc[outliers_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_list = ['bathrooms', 'bedrooms']\n",
    "target = 'price'\n",
    "\n",
    "def make_ols(df, feature_list, target):\n",
    "    \n",
    "    y = df[target]\n",
    "    X = df[feature_list]\n",
    "    \n",
    "    linreg = sm.OLS(y, X).fit()\n",
    "    summary = linreg.summary()\n",
    "    print(summary)\n",
    "    return linreg\n",
    "\n",
    "\n",
    "# linreg1 = make_ols(feature_list1)\n",
    "\n",
    "# linreg2 = make_ols(feature_list2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "* R2 = --- # good if same as R2 Adj \n",
    "* Fstat = 0.0 #if < 0.05 then we're confident in the signal from our features\n",
    "\n",
    "    * Features\n",
    "        * feature1 (eg \"sqft_living\")\n",
    "            * p = 0 -> this is probably not random\n",
    "        * feature2 (eg \"zipcode\")\n",
    "            * same\n",
    "    * Residuals\n",
    "        * SKEW: 1.18 -> pos skew\n",
    "        * Kurtosis 4.405 -> most of the data is within 4.4 stds, should be close to 3\n",
    "        * Jarque-Bera = gemoetric mean of Skewness and Kurtosis scaled to sample size (low)\n",
    "            * Compare between models (it's relative not absolute measure)\n",
    "        * Cond. No = Invertability of Feature Space\n",
    "            * High num -> multicollinearity\n",
    "            * Low num -> consistent system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forward_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sl ~ rk + yr + 1\n",
      "0.8351907605379858\n"
     ]
    }
   ],
   "source": [
    "# Choose a linear model by forward selection\n",
    "# The function below optimizes adjusted R-squared by adding features that help the most one at a time\n",
    "# until the score goes down or you run out of features.\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Example:\n",
    "import pandas as pd\n",
    "\n",
    "url = \"http://data.princeton.edu/wws509/datasets/salary.dat\"\n",
    "data = pd.read_csv(url, sep='\\\\s+')\n",
    "\n",
    "model = forward_selected(data, 'sl')\n",
    "\n",
    "print(model.model.formula)\n",
    "# sl ~ rk + yr + 1\n",
    "\n",
    "print(model.rsquared_adj)\n",
    "# 0.835190760538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sx</th>\n",
       "      <th>rk</th>\n",
       "      <th>yr</th>\n",
       "      <th>dg</th>\n",
       "      <th>yd</th>\n",
       "      <th>sl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>25</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>35</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>22</td>\n",
       "      <td>35350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>10</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>23</td>\n",
       "      <td>28200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>7</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>27</td>\n",
       "      <td>26775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>19</td>\n",
       "      <td>masters</td>\n",
       "      <td>30</td>\n",
       "      <td>33696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sx    rk  yr         dg  yd     sl\n",
       "0    male  full  25  doctorate  35  36350\n",
       "1    male  full  13  doctorate  22  35350\n",
       "2    male  full  10  doctorate  23  28200\n",
       "3  female  full   7  doctorate  27  26775\n",
       "4    male  full  19    masters  30  33696"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kc_house_data.csv')\n",
    "model = forward_selected(data, 'price')\n",
    "print(model.model.formula)\n",
    "print(model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = Q3 - Q1\n",
    "                    Q1 = 25th percentile\n",
    "                    Q3 = 75th percentils"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
