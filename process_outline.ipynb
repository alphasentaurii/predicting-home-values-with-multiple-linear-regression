{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Process Outline & Objectives\n",
    "\n",
    "    * OSEMN: OBTAIN > SCRUB > EXPLORE > MODEL > INTERPRET\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Column Names and descriptions for Kings County Data Set\n",
    "\n",
    "#### SET_INDEX\n",
    "* **id** - unique identified for a house\n",
    "\n",
    "#### TARGET\n",
    "* **pricePrice** -  is prediction target\n",
    "\n",
    "#### DATETIME\n",
    "* **dateDate** - house was sold\n",
    "* **yr_built** - Built Year\n",
    "\n",
    "#### BOOL\n",
    "* **yr_renovated** - Year when house was renovated\n",
    "* **waterfront** - House which has a view to a waterfront\n",
    "\n",
    "#### CONTINUOUS\n",
    "* **sqft_livingsquare** -  footage of the home\n",
    "(drop or combine with sqft_living if both == higher coef)\n",
    "* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors\n",
    "* **sqft_lotsquare** -  footage of the lot\n",
    "* **sqft_above** - square footage of house apart from basement\n",
    "* **sqft_basement** - square footage of the basement\n",
    "\n",
    "\n",
    "#### CATEGORICAL\n",
    "\n",
    "* **grade** - overall grade given to the housing unit, based on King County grading system\n",
    "(drop bc or multicollinearity - or combine with grade if higher coef)\n",
    "* **condition** - How good the condition is ( Overall )\n",
    "* **bathroomsNumber** -  of bathrooms/bedrooms\n",
    "* **bedroomsNumber** -  of Bedrooms/House\n",
    "* **floorsTotal** -  floors (levels) in house\n",
    "* **view** - Has been viewed\n",
    "\n",
    "* **zipcode** - zip\n",
    "(drop - redundant with zipcode)\n",
    "* **lat** - Latitude coordinate\n",
    "* **long** - Longitude coordinate\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1 - OBTAIN\n",
    "\n",
    "   ### 1.1 - Import Data, Libraries, Inspect Data Types\n",
    "   Obtain data and review data types, etc.\n",
    "       * Display header and info\n",
    "           * df.head()        \n",
    "           * df.info()\n",
    "           \n",
    "       \n",
    "   functions:\n",
    "       * def check_column(series, nlargest):\n",
    "       * def log_z(col):\n",
    "       * def rem_out_z(col_name):\n",
    "       * def multiplot(df):\n",
    "       * def plot_hist_scat(df,target,stats):\n",
    "       * def plot_hist_scat_sns(df,target,stats):\n",
    "       * def detect_outliers(df,n,features): (using IQRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - SCRUB \n",
    "\n",
    "##### Scrub 1 : categorizing / casting data types\n",
    "\n",
    "**Q1:Which predictors should be analyzed as continuous data, vs binned/categorical data?\n",
    "\n",
    "+ preliminary analysis, data casting, and visualizations\n",
    "+ check for linearity, normal distributions\n",
    "\n",
    "### Review initial data summaries\n",
    "\n",
    "       * Check and cast data types\n",
    "           * categorical variables stored as integers\n",
    "           * numbers stored as objects\n",
    "           * odd values (lots of 0's, strings that can't be converted, etc)\n",
    "               * df.info()\n",
    "               * df.unique()\n",
    "               * df.isna().sum()\n",
    "               * df.describe()-min/max, etc \n",
    "               * df.set_index\n",
    "               * df.describe()\n",
    "               * df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrub  2 : Null / Missing Values\n",
    "\n",
    "**Q2: How do we deal with missing values?**\n",
    " \n",
    "+ recast data types, remove null values\n",
    "\n",
    "          \n",
    "          * Identifying and removing **NULL VALUES**: \n",
    "              * df.isna().sum()\n",
    "          * Drop null rows or columns as appropriate\n",
    "              * df.drop() / df.drop(['col1','col2'],axis=1)\n",
    "                   * drop sqft_basement (most values = 0.0)\n",
    "                   * drop date\n",
    "          * Coarse Binning NUMERICAL Data\n",
    "              * replace with median or bin/convert to categorical\n",
    "                   * bin yr_built\n",
    "                   * bin sqft_above\n",
    "          \n",
    "          * CATEGORICAL data: \n",
    "              * make NaN own category OR replace with most common category\n",
    "              * Fill in null values and recast variables for EDA\n",
    "                   * zipcode --> coded\n",
    "                   * View --> category\n",
    "                   * Waterfront --> boolean\n",
    "                   * yr_renovated --> is_reno (boolean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrub 3: Multicollinearity\n",
    "\n",
    "**Q3: which predictors are closely related (and should be dropped)?**\n",
    "    + multicollinearity: one-hot dummy variables, data dropping\n",
    "    + remove variable having most corr with largest # of variables\n",
    "\n",
    "        * Checking for Multicollinearity\n",
    "        * use seaborn to make correlation matrix plot\n",
    "        * threshold >= 0.5 corr (rank correlations -- build custom function?) \n",
    "        * one-hot dummy variables, and data dropping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE\n",
    "\n",
    "##### EDA 1 : pre-normalization/transformation\n",
    "\n",
    "**Q4: Which categorical variables show the greatest potential as predictors?**\n",
    "Check distributions, outliers, etc\n",
    "Check scales, ranges (df.describe())\n",
    "Check histograms to get an idea of distributions and data transformations to perform\n",
    "    df.hist() \n",
    "    \n",
    "    Can also do kernel density estimates\n",
    "       + Re-check for linearity, normal distributions\n",
    "       + scatterplots to check for linearity and possible categorical variables \n",
    "            * df.plot(kind='scatter')\n",
    "            * categoricals will look like vertical lines\n",
    "            * pd.plotting.scatter_matrix to visualize possible relationships\n",
    "            * Check for linearity\n",
    "\n",
    "    **Q5: Does removal of outliers improve the distributions?**\n",
    "       * Outlier removal >> visualization\n",
    "            * Filling in df_norm\n",
    "            * Examine basic descriptive stats\n",
    "            * Visualizing numerical data\n",
    "            * Visualizing categorical data\n",
    "                * BOX PLOTS\n",
    "                    IQR / Percentiles\n",
    "                * VIOLIN PLOTS\n",
    "\n",
    "       * NORMALIZING & TRANSFORMING\n",
    "           * Normalize data (may want to do after some exploring)\n",
    "               * Most popular is Z-scoring (but won't fix skew)\n",
    "           * Can log-transform to fix skewed data\n",
    "               * (RobustScaler)\n",
    "           * CHECKING NORMALIZED DATASET\n",
    "           * Recheck multipol\n",
    "           * CAT.CODES FOR BINNED DATA\n",
    "           * Concatenate final df for modeling (df_run)\n",
    "           * Saving/loading df_run after cleaning up\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### MODEL\n",
    "* FITTING AN INTIAL MODEL:\n",
    "* Feature Selection: (Least number of features that gives you the best results)\n",
    "    * DETERMINING IDEAL FEATURES TO USE\n",
    "        * Using elbow plots to identify the best # of features to use\n",
    "        * Choosing Features Based on Rankings\n",
    "       \n",
    "    * PRELIMINARY UNIVARIATE LINEAR REGRESSION MODELING\n",
    "    Various forms, detail later...\n",
    "    Assessing the model:\n",
    "    Assess parameters (slope,intercept)\n",
    "    Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "    Are the coeffs, slopes, intercepts in appropriate units?\n",
    "    Whats the impact of collinearity? Can we ignore?\n",
    "    \n",
    "    * MULTIVARIATE REGRESSIONS\n",
    "        * Cross-Validation with K-Fold Test-Train Splits:\n",
    "            * Save df_run_ols to csv\n",
    "            * FINAL REGRESSION RESULTS\n",
    "        * K-Fold validation with OLS\n",
    "        * Q-Q Plots\n",
    "        * FINAL MODEL - New\n",
    "        * Predictor Coefficients & Their Affect On Sales Price\n",
    "        * Future Directions\n",
    "        * Revise the fitted model\n",
    "            * Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "        Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "        * Check for missed non-linearity\n",
    "        Holdout validation / Train/test split\n",
    "        * use sklearn train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERPRET\n",
    "\n",
    "* Observations\n",
    "* Conclusions\n",
    "* Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
